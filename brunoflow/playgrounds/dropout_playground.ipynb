{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([[2., 0., 0., 2., 2., 0., 0., 2., 2., 2.],\n",
      "        [2., 0., 0., 2., 2., 2., 0., 2., 0., 0.],\n",
      "        [0., 0., 2., 2., 2., 2., 2., 0., 0., 0.]], grad_fn=<MulBackward0>)\n",
      "X: tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "output grad after backprop: tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "X grad after backprop: tensor([[2., 0., 0., 2., 2., 0., 0., 2., 2., 2.],\n",
      "        [2., 0., 0., 2., 2., 2., 0., 2., 0., 0.],\n",
      "        [0., 0., 2., 2., 2., 2., 2., 0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1664405705473/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "dropout = torch.nn.Dropout(p=0.5)\n",
    "\n",
    "X = torch.ones(size=(3, 10), requires_grad=True)\n",
    "output = dropout(X)\n",
    "output.retain_grad()\n",
    "\n",
    "print(\"output:\", output)\n",
    "print(\"X:\", X)\n",
    "output.backward(gradient=torch.ones_like(output))\n",
    "print(\"output grad after backprop:\", output.grad)\n",
    "print(\"X grad after backprop:\", X.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 15:40:25.507374: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: node(name: (* (* x [[1 1 1 1 0 1 0 1 1 0]\n",
      " [1 1 1 1 0 0 0 1 1 1]\n",
      " [1 1 0 1 0 1 0 1 1 0]]) 2.0), val: [[2. 2. 2. 2. 0. 2. 0. 2. 2. 0.]\n",
      " [2. 2. 2. 2. 0. 0. 0. 2. 2. 2.]\n",
      " [2. 2. 0. 2. 0. 2. 0. 2. 2. 0.]], grad: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]])\n",
      "X: node(name: x, val: [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]], grad: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]])\n",
      "output grad after backprop: node(name: (* (* x [[1 1 1 1 0 1 0 1 1 0]\n",
      " [1 1 1 1 0 0 0 1 1 1]\n",
      " [1 1 0 1 0 1 0 1 1 0]]) 2.0), val: [[2. 2. 2. 2. 0. 2. 0. 2. 2. 0.]\n",
      " [2. 2. 2. 2. 0. 0. 0. 2. 2. 2.]\n",
      " [2. 2. 0. 2. 0. 2. 0. 2. 2. 0.]], grad: [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]])\n",
      "X grad after backprop: node(name: x, val: [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]], grad: [[2. 2. 2. 2. 0. 2. 0. 2. 2. 0.]\n",
      " [2. 2. 2. 2. 0. 0. 0. 2. 2. 2.]\n",
      " [2. 2. 0. 2. 0. 2. 0. 2. 2. 0.]])\n"
     ]
    }
   ],
   "source": [
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import brunoflow as bf\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "dropout_bf = bf.net.Dropout(p=0.5)\n",
    "dropout_bf.training = True\n",
    "X = bf.Node(jnp.ones(shape=(3, 10)), name=\"x\")\n",
    "\n",
    "output = dropout_bf(X)\n",
    "output.zero_gradients()\n",
    "\n",
    "print(\"output:\", output)\n",
    "print(\"X:\", X)\n",
    "output.backprop()\n",
    "print(\"output grad after backprop:\", output)\n",
    "print(\"X grad after backprop:\", X) # note that the grad is only non-zero for the values that were not dropped out (matches value of output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('jax-hf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4cc9cc217af6b7e12b7da5c82d5884fde07a0e0f6b7f76767c2fbf53f076f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
