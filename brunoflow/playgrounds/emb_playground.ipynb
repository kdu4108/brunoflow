{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brunoflow as bf\n",
    "from brunoflow.ad.utils import check_node_equals_tensor\n",
    "from jax import numpy as jnp, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "random_key_val = 42\n",
    "num_embeddings = 5\n",
    "embedding_dim = 3\n",
    "padding_idx = 1\n",
    "random_key = random.PRNGKey(random_key_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.7230,  2.1811,  0.9185],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [-0.4263, -0.4424, -0.3087],\n",
       "        [-0.8633,  0.3375,  0.3774],\n",
       "        [-0.5210,  0.2912, -0.6680]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and inspect a torch embedding\n",
    "import torch\n",
    "emb = torch.nn.Embedding(num_embeddings=5, embedding_dim=3, padding_idx=1)\n",
    "emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Create and inspect a bf Embedding\u001b[39;00m\n\u001b[1;32m      2\u001b[0m emb_bf \u001b[39m=\u001b[39m bf\u001b[39m.\u001b[39mnet\u001b[39m.\u001b[39mEmbedding(num_embeddings\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, embedding_dim\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, padding_idx\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m bf\u001b[39m.\u001b[39;49mmatmul(emb_bf([\u001b[39m2\u001b[39;49m]), jnp\u001b[39m.\u001b[39;49mones(shape\u001b[39m=\u001b[39;49m(\u001b[39m3\u001b[39;49m, \u001b[39m4\u001b[39;49m)))\u001b[39m.\u001b[39;49mbackprop()\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(emb_bf\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mgrad)\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/ad/node.py:241\u001b[0m, in \u001b[0;36mNode.backprop\u001b[0;34m(self, values_to_compute, save_leaf_grads_only, verbose)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    227\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    228\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, num_uses:\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad),\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__compute_num_uses()\n\u001b[0;32m--> 241\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__backprop(values_to_compute\u001b[39m=\u001b[39;49mvalues_to_compute, verbose\u001b[39m=\u001b[39;49mverbose, save_leaf_grads_only\u001b[39m=\u001b[39;49msave_leaf_grads_only)\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/ad/node.py:482\u001b[0m, in \u001b[0;36mNode.__backprop\u001b[0;34m(self, values_to_compute, save_leaf_grads_only, verbose)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[39mfor\u001b[39;00m inp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs:\n\u001b[1;32m    481\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inp, Node):\n\u001b[0;32m--> 482\u001b[0m         inp\u001b[39m.\u001b[39;49m__backprop(\n\u001b[1;32m    483\u001b[0m             values_to_compute\u001b[39m=\u001b[39;49mvalues_to_compute, verbose\u001b[39m=\u001b[39;49mverbose, save_leaf_grads_only\u001b[39m=\u001b[39;49msave_leaf_grads_only\n\u001b[1;32m    484\u001b[0m         )\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/ad/node.py:460\u001b[0m, in \u001b[0;36mNode.__backprop\u001b[0;34m(self, values_to_compute, save_leaf_grads_only, verbose)\u001b[0m\n\u001b[1;32m    458\u001b[0m input_vals \u001b[39m=\u001b[39m [inp\u001b[39m.\u001b[39mval \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inp, Node) \u001b[39melse\u001b[39;00m inp \u001b[39mfor\u001b[39;00m inp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs]\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mgrad\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m values_to_compute:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_and_accumulate_grads_for_inputs(\n\u001b[1;32m    461\u001b[0m         input_vals\u001b[39m=\u001b[39;49minput_vals, backward_func\u001b[39m=\u001b[39;49mbackward_func, verbose\u001b[39m=\u001b[39;49mverbose\n\u001b[1;32m    462\u001b[0m     )\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmax_grad\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m values_to_compute:\n\u001b[1;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_and_accumulate_max_pos_and_neg_grads_for_inputs(\n\u001b[1;32m    465\u001b[0m         input_vals\u001b[39m=\u001b[39minput_vals, backward_func\u001b[39m=\u001b[39mbackward_func, verbose\u001b[39m=\u001b[39mverbose\n\u001b[1;32m    466\u001b[0m     )\n",
      "File \u001b[0;32m~/code/rycolab/brunoflow/brunoflow/ad/node.py:248\u001b[0m, in \u001b[0;36mNode._compute_and_accumulate_grads_for_inputs\u001b[0;34m(self, input_vals, backward_func, verbose)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_compute_and_accumulate_grads_for_inputs\u001b[39m(\u001b[39mself\u001b[39m, input_vals, backward_func, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    244\u001b[0m     \u001b[39m# The 'adjoint' is the partial derivative of the final node in the graph\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[39m#   (typically the loss) w.r.t. the value at this Node.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     adjoints \u001b[39m=\u001b[39m backward_func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad, \u001b[39m*\u001b[39minput_vals)\n\u001b[0;32m--> 248\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(input_vals) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(adjoints)\n\u001b[1;32m    249\u001b[0m     \u001b[39m# Accumulate these adjoints into the gradients for this Node's inputs\u001b[39;00m\n\u001b[1;32m    250\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(adjoints)):\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create and inspect a bf Embedding\n",
    "emb_bf = bf.net.Embedding(num_embeddings=5, embedding_dim=3, padding_idx=1)\n",
    "bf.matmul(emb_bf([2]), jnp.ones(shape=(3, 4))).backprop()\n",
    "print(emb_bf.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/miniconda3/envs/jax-hf/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1664405705473/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [4., 4., 4.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect grad for a non-pad token - note that the grad is the same for bf and torch!\n",
    "out = torch.matmul(emb(torch.tensor([2])), torch.ones(size=(3, 4), requires_grad=True))\n",
    "out.backward(gradient=torch.ones_like(out))\n",
    "assert(jnp.array_equal(emb_bf.weight.grad, emb.weight.grad))\n",
    "emb.weight.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [4., 4., 4.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect grad for a pad token for torch - note that the grad DID NOT change from before in the 1st (pad token index) row\n",
    "out = torch.matmul(emb(torch.tensor([1])), torch.ones(size=(3, 4), requires_grad=True))\n",
    "out.backward(gradient=torch.ones_like(out))\n",
    "emb.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [4. 4. 4.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Inspect grad for a pad token for bf, note that the grad DID NOT change from before in the pad token index. Same behavior as torch\n",
    "bf.matmul(emb_bf([1]), jnp.ones(shape=(3, 4))).backprop()\n",
    "print(emb_bf.weight.grad)\n",
    "assert(jnp.array_equal(emb_bf.weight.grad, emb.weight.grad.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bf modules: [Embedding(5, 3, padding_idx=1)]\n",
      "torch modules: [Embedding(5, 3, padding_idx=1)]\n"
     ]
    }
   ],
   "source": [
    "# Check that bf and torch embedding contain the same modules \n",
    "print(\"bf modules:\", [i for i in emb_bf.modules()])\n",
    "print(\"torch modules:\", [i for i in emb.modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[node(name: emb weights (5, 3), val: [[-0.716899   -0.20865498 -2.5713923 ]\n",
      " [ 0.          0.          0.        ]\n",
      " [-0.8396519   0.3010434   0.1421263 ]\n",
      " [-1.7631724  -1.6755073   0.31390068]\n",
      " [ 0.5912831   0.5325395  -0.9133108 ]], grad: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [4. 4. 4.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]])]\n",
      "[(Parameter containing:\n",
      "tensor([[ 0.2225,  0.1144, -0.3670],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.8473, -0.0814, -0.0372],\n",
      "        [ 0.0992,  0.0027,  0.1115],\n",
      "        [-0.7348, -0.7790, -0.2488]], requires_grad=True), tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [4., 4., 4.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]))]\n"
     ]
    }
   ],
   "source": [
    "# Check that we can access parameters of both bf and torch embeddings\n",
    "print([i for i in emb_bf.parameters()])\n",
    "print([(i, i.grad) for i in emb.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Check that buffers are the same between bf and torch embeddings\n",
    "print([i for i in emb_bf.buffers()])\n",
    "print([i for i in emb.buffers()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a torch embedding state dict and reloading it as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_torch_path = \"emb.pt\"\n",
    "torch.save(emb.state_dict(), save_torch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_loaded = torch.nn.Embedding(num_embeddings=5, embedding_dim=3, padding_idx=1)\n",
    "emb_loaded.load_state_dict(torch.load(save_torch_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node(name: emb weights (5, 3), val: [[ 0.22245939  0.11442263 -0.3670383 ]\n",
      " [ 0.          0.          0.        ]\n",
      " [-0.8473086  -0.08135143 -0.03718618]\n",
      " [ 0.09916912  0.00267494  0.11154094]\n",
      " [-0.7347803  -0.77901185 -0.24880375]], grad: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.2225,  0.1144, -0.3670],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.8473, -0.0814, -0.0372],\n",
      "        [ 0.0992,  0.0027,  0.1115],\n",
      "        [-0.7348, -0.7790, -0.2488]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# check that bf embedding when loading from a torch state dict ends up with same values\n",
    "emb_bf_loaded = bf.net.Embedding(num_embeddings=5, embedding_dim=3, padding_idx=1)\n",
    "emb_bf_loaded.load_state_dict(torch.load(save_torch_path))\n",
    "print(emb_bf_loaded.weight)\n",
    "print(emb_loaded.weight)\n",
    "assert(check_node_equals_tensor(emb_bf_loaded.weight, emb_loaded.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bf output of emb: node(name: get_embedding, val: [[ 0.          0.          0.        ]\n",
      " [-0.8473086  -0.08135143 -0.03718618]\n",
      " [ 0.09916912  0.00267494  0.11154094]], grad: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]])\n",
      "torch output of emb: tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.8473, -0.0814, -0.0372],\n",
      "        [ 0.0992,  0.0027,  0.1115]], grad_fn=<EmbeddingBackward0>)\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]] tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Check forward and backward passes to make sure the outputs match\n",
    "inds = [1,2,3]\n",
    "embs_bf_out = emb_bf_loaded(jnp.array(inds))\n",
    "embs_out = emb_loaded(torch.tensor(inds))\n",
    "print(\"bf output of emb:\", embs_bf_out)\n",
    "print(\"torch output of emb:\", embs_out)\n",
    "assert(check_node_equals_tensor(embs_bf_out, embs_out))\n",
    "\n",
    "embs_bf_out.backprop()\n",
    "embs_out.backward(gradient=torch.ones_like(embs_out))\n",
    "# print(embs_bf_out.grad, embs_out.grad)\n",
    "assert(jnp.array_equal(emb_bf_loaded.weight.grad, emb_loaded.weight.grad.numpy()))\n",
    "print(emb_bf_loaded.weight.grad, emb_loaded.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "emb_bf_loaded = bf.net.Embedding(num_embeddings=5, embedding_dim=3, padding_idx=1)\n",
    "emb_bf_loaded.load_state_dict(torch.load(save_torch_path))\n",
    "out = bf.get_embedding(emb_bf_loaded.weight, [0, 1, 2, 3, 4], padding_idx=1)\n",
    "out.backprop()\n",
    "print(emb_bf_loaded.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('jax-hf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4cc9cc217af6b7e12b7da5c82d5884fde07a0e0f6b7f76767c2fbf53f076f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
